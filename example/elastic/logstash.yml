input {
  beats {
    port => 5044
  }
}



filter {
    if "AUTOMATION" in [tags] {
        date {
            match => [ "[automation][ts]", "ISO8601", "YYYY-MM-dd HH:mm:ss", "YYYY-MM-dd HH:mm:ss.ZZZ", "UNIX" ]
            target => "@timestamp"
            locale => "en"
        }
        ruby {
            code => '
            t = event.get("@timestamp")
            event.set("automation_timestamp_fixed", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
        }
    }

}


filter {
    if "MULTILINE" in [tags] {
        grok {
            match => {"message" => "%{TIMESTAMP_ISO8601:nuix_timestamp} %{NUMBER:nuix_timezone} \[%{DATA:nuix_source}] %{NUMBER:nuix_thread} %{LOGLEVEL:nuix_loglevel}%{SPACE}%{DATA:nuix_class} - (?<nuix_short_message>[\s\S]{0,50})%{DATA:nuix_second_short_message}\n(?m)%{GREEDYDATA:nuix_multilines}"}
        }
    } else if "AUTOMATION" in [tags]  {
        grok {
            match => {"message" => "%{LOGLEVEL:level}%{GREEDYDATA:log_message}"}
        }   
    } else if "METRICBEAT" in [tags]  {
        grok {
            match => {"message" => "%{GREEDYDATA:log_message}"}
        }   
    } else if "_grokparsefailure" in [tags]  {
        grok {
            match => {"message" => "%{GREEDYDATA:log_message}"}        
        }
    } else if "OCR-LOG" in [tags]  {
        grok {
            match => {"message" => "%{GREEDYDATA:log_message}"}
        }
    } else if "ABBY-WORKER-LOG" in [tags]  {
        grok {
            match => {"message" => "%{GREEDYDATA:log_message}"}
        }        
    } else {
        grok {
            match => {"message" => "%{TIMESTAMP_ISO8601:nuix_timestamp} %{NUMBER:nuix_timezone} \[%{DATA:nuix_source}] %{NUMBER:nuix_thread} %{LOGLEVEL:nuix_loglevel}%{SPACE}%{DATA:nuix_class} - %{GREEDYDATA:automation_status}"}
        }
    }
      
     # Kolla så att runner-start finns med i taggen
    if "NUIX-RUNNER-START" in [tags] {
        # kör ett ruby-script på eventet
        ruby {
            code => '
                # sätt ett nytt event som är en map kallad för nuix_log
                event.set("[nuix_log]", {
                    # Lägg till runner i mappen, som kommer från från eventet nuix_class (formaterat från grok-filtret)
                    # ta bort prefix SCRIPT. och suffix .gen från denna
                    "runner" => event.get("nuix_class").delete_prefix("SCRIPT.").delete_suffix(".gen"),
                    # Lägg till path i mapppen (alltså vart loggen ligger)
                    "path" => File.dirname(event.get("[log][file][path]")),
                    # Lägg även till host i mappen
                    "host" => event.get("[agent][hostname]"),
                })
            '
        }
        # Sen startar vi en aggregate
        aggregate {
            # Då behöver vi ett task-id för att veta vilka entries som ska behandlas
            task_id => "%{[nuix_log][host]}"
            # Då¨skapar vi en ny mapp i denna "task", med nyckeln path för loggen
            # värdet för nyckeln är nuix_log entryt som vi skapar i ruby koden ovanför
            code => "map[event.get('[nuix_log][path]')] = event.get('[nuix_log]')"
            # skapas mappen med "create"
            map_action => "create"
#            push_previous_map_as_event => true
            #timeout => 86400
        }
    # När vi får ett runner-end entry ska vi avsluta aggregate (tasken)
    # för att ta bort mappen som har skapats
    } else if "NUIX-RUNNER-END" in [tags] {
        # ruby script för att sätta nuix_log.host
        ruby {
            code => 'event.set("[nuix_log][host]", event.get("[agent][hostname]"))'
        }
        # starta aggregate
        aggregate {
            # sätt task_id till hostname
            task_id => "%{[nuix_log][host]}"
            # kör ruby-script
            code => '
                # skapa variabel för log_dir
                log_dir = File.dirname(event.get("[log][file][path]"))
                # kolla så att log_dir finns i mappen
                if map.key?(log_dir)
                    # sätt fältet nuix_log från värdet i map med nyckeln log_dir
                    event.set("[nuix_log]", map[log_dir])
                end
            '
            # uppdatera mappen
#            push_previous_map_as_event => true 
            timeout => 2629743
            inactivity_timeout => 300            
            map_action => "update"                    
            # avsluta tasken (eftersom vi har fått runner-end)
            end_of_task => true           
        }
    } else {
        # ruby script för att sätta nuix_log.host
        ruby {
            code => 'event.set("[nuix_log][host]", event.get("[agent][hostname]"))'
        }
        # starta aggregate
        aggregate {
            # sätt task_id till hostname
            task_id => "%{[nuix_log][host]}"
            # kör ruby-script
            code => '
                # sätt log_dir som variabel
                log_dir = File.dirname(event.get("[log][file][path]"))
                # loopa sex gånger (eftersom det finns sub-directories till vissa loggar)
                 (0..6).each do |i|
                    # om log_dir finns i mappen
                    if map.key?(log_dir)
                        # sätt fältet nuix_log från värdet i map med nyckeln log_dir
                        event.set("[nuix_log]", map[log_dir])
                        # breakea loopen
                        break
                    end
                    # ta bort sub-directory från variabeln
                    # om den inte finns med i mappen
                    log_dir = File.dirname(log_dir)
                end
            '
            # uppdatera mappen
            map_action => "update"            
#            timeout => 86400
#            inactivity_timeout => 300
        }
    }
}

filter {
    if "NUIX-SINGLE-WORKER" in [tags] {
        mutate { convert => ["process_pid", "string"] }
        ruby {
            code => '
                   event.set("nuix_running_worker", event.get("[process][name]") + "-" + event.get("process_pid"))                 
            '
        }
    }
}

#filter {
#    if "DISK-SPACE-UTIL" in [tags] {
#        mutate { convert => ["[system][filesystem][used][bytes]", "string"] }
#        mutate { convert => ["[system][filesystem][total]", "string"] }        
#        mutate {
#            add_field => {
#                "nuix_disc_event" => " Drive %{[system][filesystem][device_name]} %{[system][filesystem][used][bytes]} of %{[system][filesystem][total]}"
#            }
#        }
#    }
#}

#filter {
#    if "DISK-SPACE-UTIL" in [tags] {
#        mutate { convert => ["system_filesystem_free", "string"] }
#        mutate { convert => ["system_filesystem_total", "string"] } 
#        mutate {
#            add_field => {
#                "nuix_disc_event" => " Drive %{[system][filesystem][device_name]} %{system_filesystem_free} of %{system_filesystem_total}"
#        }    
#    }
#}


############ From here Metricbeat

#event.set("nuix_running_worker", "Host=" + event.get("[agent][hostname]") + event.get("[process][name]") + event.get("process_pid"))

filter {
    if "NUIX-LOG" in [tags] {
        date {
            match => [ "nuix_timestamp", "ISO8601", "YYYY-MM-dd HH:mm:ss", "YYYY-MM-dd HH:mm:ss.ZZZ" ]
            target => "@timestamp"
            locale => "en"
        }
    }

}


filter {
    if "RU" in [tags] {        
        elapsed {
            start_tag => "STARTING-RUNNER"
            end_tag => "ENDING-RUNNER"
            periodic_flush => false
            unique_id_field => "runner"
            timeout => 2629743
            new_event_on_match => false
        }        
    } else if "ST" in [tags] {        
        elapsed {
            start_tag => "STARTING-STAGE"
            end_tag => "ENDING-STAGE"
            periodic_flush => false
            unique_id_field => "[automation][stage_id]"
            timeout => 2629743
            new_event_on_match => false
        }        
    }
}

filter {
    if [elapsed_time] {
         ruby {
            code => '
                event.set("[elapsed_hr]", Time.at(event.get("[elapsed_time]")).utc.strftime("%T.%L"))
            '
        }
    }
}

filter {
   if "STARTING-RUNNER" in [tags] {
        ruby {
        code => '
            t = event.get("@timestamp")
            event.set("elapsed_timestamp_event_start_runner", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
        }
        mutate {
            add_field => { "elapsed_timestamp_event_end_runner" => "--------------->" }
        }        
        mutate {
            add_field => { "elapsed_hr" => "Runner Started" }
        }
    }
  }

filter {
   if "STARTING-STAGE" in [tags] {
        ruby {
        code => '
            t = event.get("@timestamp")
            event.set("elapsed_timestamp_event_start_stage", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
        }
        mutate {
            add_field => { "elapsed_timestamp_event_end_stage" => "--------------->" }
        }        
        mutate {
            add_field => { "elapsed_hr" => "Stage Started" }
        }
    }
  }

filter {
   if "ENDING-STAGE" in [tags] {
        ruby {
        code => '
            t = event.get("elapsed_timestamp_start")
            event.set("elapsed_timestamp_event_start_stage", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
    }
  }
}

filter {
   if "ENDING-RUNNER" in [tags] {
        ruby {
        code => '
            t = event.get("elapsed_timestamp_start")
            event.set("elapsed_timestamp_event_start_runner", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
    }
  }
}



filter {
   if "AUTOMATION-FINISHED-STAGE" in [tags] {
        ruby {
        code => '
            t = event.get("@timestamp")
            event.set("elapsed_timestamp_event_end_stage", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
    }
  }
}

filter {
   if "AUTOMATION-FINISHED-RUNNER" in [tags] {
        ruby {
        code => '
            t = event.get("@timestamp")
            event.set("elapsed_timestamp_event_end_runner", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
    }
  }
}


filter {
  mutate {
    remove_tag => [ "beats_input_codec_plain_applied", "beats_input_raw_event" ]
  }
}

output {
  elasticsearch {
    hosts => ["http://${ES_HOST}:9200"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}
