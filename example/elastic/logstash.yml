input {
  beats {
    port => 5044
  }
}

filter {
    if "AUTOMATION" in [tags] {
        date {
            match => [ "[automation][ts]", "UNIX"]
            target => "time-test1"
            }
        ruby {
            code => "event.set('[automation][ts]',event.get('[automation][ts]')+ 3600)"
        }    
        date {
            match => [ "[automation][ts]", "UNIX"]
            target => "[automation][timestamp]"
        }
        ruby {
        code => '
            t = event.get("time-test1")
            event.set("automation_timestamp_fixed", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
        }
#        date {
#            match => [ "automation_timestamp_fixed", "yyyy-MM-dd HH:mm:ss"]
#            target => "[automation][timestamp][fixed]"
        
#        }
    }
}

#code => 'event.set("[nuix_log][host]", event.get("[agent][hostname]"))'


filter {
    if "MULTILINE" in [tags] {
        grok {
            match => {"message" => "%{TIMESTAMP_ISO8601:nuix_timestamp} %{NUMBER:nuix_timezone} \[%{DATA:nuix_source}] %{NUMBER:nuix_thread} %{LOGLEVEL:nuix_loglevel}%{SPACE}%{DATA:nuix_class} - (?<nuix_short_message>[\s\S]{0,50})%{DATA:nuix_second_short_message}\n(?m)%{GREEDYDATA:nuix_multilines}"}
        }
    } else if "AUTOMATION" in [tags]  {
        grok {
            match => {"message" => "%{LOGLEVEL:level}%{GREEDYDATA:log_message}"}
        }   
    } else if "_grokparsefailure" in [tags]  {
        grok {
            match => {"message" => "%{GREEDYDATA:log_message}"}
        }
    } else if "OCR-LOG" in [tags]  {
        grok {
            match => {"message" => "%{GREEDYDATA:log_message}"}
        }
    } else if "ABBY-WORKER-LOG" in [tags]  {
        grok {
            match => {"message" => "%{GREEDYDATA:log_message}"}
        }        
    } else {
        grok {
            match => {"message" => "%{TIMESTAMP_ISO8601:nuix_timestamp} %{NUMBER:nuix_timezone} \[%{DATA:nuix_source}] %{NUMBER:nuix_thread} %{LOGLEVEL:nuix_loglevel}%{SPACE}%{DATA:nuix_class} - %{GREEDYDATA:automation_status}"}
        }
    }
      
     # Kolla så att runner-start finns med i taggen
    if "NUIX-RUNNER-START" in [tags] {
        # kör ett ruby-script på eventet
        ruby {
            code => '
                # sätt ett nytt event som är en map kallad för nuix_log
                event.set("[nuix_log]", {
                    # Lägg till runner i mappen, som kommer från från eventet nuix_class (formaterat från grok-filtret)
                    # ta bort prefix SCRIPT. och suffix .gen från denna
                    "runner" => event.get("nuix_class").delete_prefix("SCRIPT.").delete_suffix(".gen"),
                    # Lägg till path i mapppen (alltså vart loggen ligger)
                    "path" => File.dirname(event.get("[log][file][path]")),
                    # Lägg även till host i mappen
                    "host" => event.get("[agent][hostname]"),
                })
            '
        }
        # Sen startar vi en aggregate
        aggregate {
            # Då behöver vi ett task-id för att veta vilka entries som ska behandlas
            task_id => "%{[nuix_log][host]}"
            # Då¨skapar vi en ny mapp i denna "task", med nyckeln path för loggen
            # värdet för nyckeln är nuix_log entryt som vi skapar i ruby koden ovanför
            code => "map[event.get('[nuix_log][path]')] = event.get('[nuix_log]')"
            # skapas mappen med "create"
            map_action => "create"
#            push_previous_map_as_event => true
            #timeout => 86400
        }
    # När vi får ett runner-end entry ska vi avsluta aggregate (tasken)
    # för att ta bort mappen som har skapats
    } else if "NUIX-RUNNER-END" in [tags] {
        # ruby script för att sätta nuix_log.host
        ruby {
            code => 'event.set("[nuix_log][host]", event.get("[agent][hostname]"))'
        }
        # starta aggregate
        aggregate {
            # sätt task_id till hostname
            task_id => "%{[nuix_log][host]}"
            # kör ruby-script
            code => '
                # skapa variabel för log_dir
                log_dir = File.dirname(event.get("[log][file][path]"))
                # kolla så att log_dir finns i mappen
                if map.key?(log_dir)
                    # sätt fältet nuix_log från värdet i map med nyckeln log_dir
                    event.set("[nuix_log]", map[log_dir])
                end
            '
            # uppdatera mappen
#            push_previous_map_as_event => true 
            timeout => 86400
            inactivity_timeout => 300            
            map_action => "update"                    
            # avsluta tasken (eftersom vi har fått runner-end)
            end_of_task => true           
        }
    } else {
        # ruby script för att sätta nuix_log.host
        ruby {
            code => 'event.set("[nuix_log][host]", event.get("[agent][hostname]"))'
        }
        # starta aggregate
        aggregate {
            # sätt task_id till hostname
            task_id => "%{[nuix_log][host]}"
            # kör ruby-script
            code => '
                # sätt log_dir som variabel
                log_dir = File.dirname(event.get("[log][file][path]"))
                # loopa sex gånger (eftersom det finns sub-directories till vissa loggar)
                 (0..6).each do |i|
                    # om log_dir finns i mappen
                    if map.key?(log_dir)
                        # sätt fältet nuix_log från värdet i map med nyckeln log_dir
                        event.set("[nuix_log]", map[log_dir])
                        # breakea loopen
                        break
                    end
                    # ta bort sub-directory från variabeln
                    # om den inte finns med i mappen
                    log_dir = File.dirname(log_dir)
                end
            '
            # uppdatera mappen
            map_action => "update"            
#            timeout => 86400
#            inactivity_timeout => 300
        }
    }
}





filter {

    mutate { add_field => { "runner" => "%{[automation][runner]}" } }
    
    elapsed {
      start_tag => "STARTING-RUNNER"
      end_tag => "ENDING-RUNNER"
#      periodic_flush => true
      unique_id_field => "runner"
      timeout => 86400
      new_event_on_match => false
    }
    
    elapsed {
      start_tag => "STARTING-STAGE"
      end_tag => "ENDING-STAGE"
#      periodic_flush => true
      unique_id_field => "runner"
      timeout => 86400
      new_event_on_match => false
    }
    
    if [elapsed_time] {
         ruby {
            code => '
                event.set("[elapsed_hr]", Time.at(event.get("[elapsed_time]")).utc.strftime("%H:%M:%S"))
            '
        }
    }
}


filter {
   if "STARTING-RUNNER" in [tags] {
        ruby {
        code => '
            t = event.get("time-test1")
            event.set("elapsed_timestamp_event_start_runner", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
        }
        mutate {
            add_field => { "elapsed_timestamp_event_end_runner" => "Still Running" }
        }        
        mutate {
            add_field => { "elapsed_hr" => "Still Running" }
        }
    }
  }

filter {
   if "STARTING-STAGE" in [tags] {
        ruby {
        code => '
            t = event.get("time-test1")
            event.set("elapsed_timestamp_event_start_stage", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
        }
        mutate {
            add_field => { "elapsed_timestamp_event_end_stage" => "Still Running" }
        }        
        mutate {
            add_field => { "elapsed_hr" => "Still Running" }
        }
    }
  }

filter {
   if "ENDING-STAGE" in [tags] {
        ruby {
        code => '
            t = event.get("elapsed_timestamp_start")
            event.set("elapsed_timestamp_event_start_stage", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
    }
  }
}

filter {
   if "ENDING-RUNNER" in [tags] {
        ruby {
        code => '
            t = event.get("elapsed_timestamp_start")
            event.set("elapsed_timestamp_event_start_runner", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
    }
  }
}



filter {
   if "AUTOMATION-FINISHED-STAGE" in [tags] {
        ruby {
        code => '
            t = event.get("@timestamp")
            event.set("elapsed_timestamp_event_end_stage", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
    }
  }
}

filter {
   if "AUTOMATION-FINISHED-RUNNER" in [tags] {
        ruby {
        code => '
            t = event.get("@timestamp")
            event.set("elapsed_timestamp_event_end_runner", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
    }
  }
}

    

filter {
  mutate {
    remove_tag => [ "beats_input_codec_plain_applied" ]
  }
}

output {
  elasticsearch {
    hosts => ["http://${ES_HOST}:9200"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}
