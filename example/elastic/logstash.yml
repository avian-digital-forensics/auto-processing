input {
  beats {
    port => 5044
  }
}

#filter {
#    if "AUTOMATION" in [tags] {
#        date {
#            match => [ "[automation][ts]", "UNIX"]
#            target => "time-test1"
#            }
#        ruby {
#            code => "event.set('[automation][ts]',event.get('[automation][ts]')+ 3600)"
#        }    
#        date {
#            match => [ "[automation][ts]", "UNIX"]
#            target => "[automation][timestamp]"
#        }
#        ruby {
#        code => '
#            t = event.get("time-test1")
#            event.set("automation_timestamp_fixed", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
#        '
#        }
#
#    }
#}

#code => 'event.set("[nuix_log][host]", event.get("[agent][hostname]"))'


filter {
    if "AUTOMATION" in [tags] {
        date {
            match => [ "[automation][ts]", "ISO8601", "YYYY-MM-dd HH:mm:ss", "YYYY-MM-dd HH:mm:ss.ZZZ", "UNIX" ]
            target => "@timestamp"
            locale => "en"
        }
        ruby {
            code => '
            t = event.get("@timestamp")
            event.set("automation_timestamp_fixed", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
        }
    }

}








filter {
    if "MULTILINE" in [tags] {
        grok {
            match => {"message" => "%{TIMESTAMP_ISO8601:nuix_timestamp} %{NUMBER:nuix_timezone} \[%{DATA:nuix_source}] %{NUMBER:nuix_thread} %{LOGLEVEL:nuix_loglevel}%{SPACE}%{DATA:nuix_class} - (?<nuix_short_message>[\s\S]{0,50})%{DATA:nuix_second_short_message}\n(?m)%{GREEDYDATA:nuix_multilines}"}
        }
    } else if "AUTOMATION" in [tags]  {
        grok {
            match => {"message" => "%{LOGLEVEL:level}%{GREEDYDATA:log_message}"}
        }   
    } else if "_grokparsefailure" in [tags]  {
        grok {
            match => {"message" => "%{GREEDYDATA:log_message}"}
        }
    } else if "OCR-LOG" in [tags]  {
        grok {
            match => {"message" => "%{GREEDYDATA:log_message}"}
        }
    } else if "ABBY-WORKER-LOG" in [tags]  {
        grok {
            match => {"message" => "%{GREEDYDATA:log_message}"}
        }        
    } else {
        grok {
            match => {"message" => "%{TIMESTAMP_ISO8601:nuix_timestamp} %{NUMBER:nuix_timezone} \[%{DATA:nuix_source}] %{NUMBER:nuix_thread} %{LOGLEVEL:nuix_loglevel}%{SPACE}%{DATA:nuix_class} - %{GREEDYDATA:automation_status}"}
        }
    }
      
     # Kolla så att runner-start finns med i taggen
    if "NUIX-RUNNER-START" in [tags] {
        # kör ett ruby-script på eventet
        ruby {
            code => '
                # sätt ett nytt event som är en map kallad för nuix_log
                event.set("[nuix_log]", {
                    # Lägg till runner i mappen, som kommer från från eventet nuix_class (formaterat från grok-filtret)
                    # ta bort prefix SCRIPT. och suffix .gen från denna
                    "runner" => event.get("nuix_class").delete_prefix("SCRIPT.").delete_suffix(".gen"),
                    # Lägg till path i mapppen (alltså vart loggen ligger)
                    "path" => File.dirname(event.get("[log][file][path]")),
                    # Lägg även till host i mappen
                    "host" => event.get("[agent][hostname]"),
                })
            '
        }
        # Sen startar vi en aggregate
        aggregate {
            # Då behöver vi ett task-id för att veta vilka entries som ska behandlas
            task_id => "%{[nuix_log][host]}"
            # Då¨skapar vi en ny mapp i denna "task", med nyckeln path för loggen
            # värdet för nyckeln är nuix_log entryt som vi skapar i ruby koden ovanför
            code => "map[event.get('[nuix_log][path]')] = event.get('[nuix_log]')"
            # skapas mappen med "create"
            map_action => "create"
#            push_previous_map_as_event => true
            #timeout => 86400
        }
    # När vi får ett runner-end entry ska vi avsluta aggregate (tasken)
    # för att ta bort mappen som har skapats
    } else if "NUIX-RUNNER-END" in [tags] {
        # ruby script för att sätta nuix_log.host
        ruby {
            code => 'event.set("[nuix_log][host]", event.get("[agent][hostname]"))'
        }
        # starta aggregate
        aggregate {
            # sätt task_id till hostname
            task_id => "%{[nuix_log][host]}"
            # kör ruby-script
            code => '
                # skapa variabel för log_dir
                log_dir = File.dirname(event.get("[log][file][path]"))
                # kolla så att log_dir finns i mappen
                if map.key?(log_dir)
                    # sätt fältet nuix_log från värdet i map med nyckeln log_dir
                    event.set("[nuix_log]", map[log_dir])
                end
            '
            # uppdatera mappen
#            push_previous_map_as_event => true 
            timeout => 86400
            inactivity_timeout => 300            
            map_action => "update"                    
            # avsluta tasken (eftersom vi har fått runner-end)
            end_of_task => true           
        }
    } else {
        # ruby script för att sätta nuix_log.host
        ruby {
            code => 'event.set("[nuix_log][host]", event.get("[agent][hostname]"))'
        }
        # starta aggregate
        aggregate {
            # sätt task_id till hostname
            task_id => "%{[nuix_log][host]}"
            # kör ruby-script
            code => '
                # sätt log_dir som variabel
                log_dir = File.dirname(event.get("[log][file][path]"))
                # loopa sex gånger (eftersom det finns sub-directories till vissa loggar)
                 (0..6).each do |i|
                    # om log_dir finns i mappen
                    if map.key?(log_dir)
                        # sätt fältet nuix_log från värdet i map med nyckeln log_dir
                        event.set("[nuix_log]", map[log_dir])
                        # breakea loopen
                        break
                    end
                    # ta bort sub-directory från variabeln
                    # om den inte finns med i mappen
                    log_dir = File.dirname(log_dir)
                end
            '
            # uppdatera mappen
            map_action => "update"            
#            timeout => 86400
#            inactivity_timeout => 300
        }
    }
}

filter {
    if "NUIX-LOG" in [tags] {
        date {
            match => [ "nuix_timestamp", "ISO8601", "YYYY-MM-dd HH:mm:ss", "YYYY-MM-dd HH:mm:ss.ZZZ" ]
            target => "@timestamp"
            locale => "en"
        }
    }

}
###############
filter {
    if "RU" in [tags] {        
        elapsed {
            start_tag => "STARTING-RUNNER"
            end_tag => "ENDING-RUNNER"
            periodic_flush => false
            unique_id_field => "host_name"
            timeout => 86400
            new_event_on_match => false
        }        
    }
}

##############
filter {
    if "ST" in [tags] {        
        elapsed {
            start_tag => "STARTING-STAGE"
            end_tag => "ENDING-STAGE"
            periodic_flush => false
            unique_id_field => "host_name"
            timeout => 86400
            new_event_on_match => false
        }        
    }
}


#filter {
#   grok {
#     match => [ "message", "%{LOGLEVEL:loglevel} - %{NOTSPACE:taskid} - %{NOTSPACE:logger} - %{WORD:label}( - %{INT:duration:int})?" ]
#   }

#   if [starting_runner] == "STARTING-RUNNER" {
#     aggregate {
#       task_id => "%{host_name}"
#       code => "map['sql_duration'] = 0"
#       code => "map['start_timestamp'] = event['@timestamp']"
#       map_action => "create"
#     }
#   }

#   if [logger] == "SQL" {
#     aggregate {
#       task_id => "%{taskid}"
#       code => "map['sql_duration'] += event.get('duration')"
#       map_action => "update"
#     }
#   }

#   if [ending_runner] == "ENDING-RUNNER" {
#     aggregate {
#       task_id => "%{host_name}"
#       code => 'event.set("[elapsed_hr1]", event["@timestamp"] - map["start_timestamp"])'
#       map_action => "update"
#       timeout => 120
#    }

#   }
# }


#filter {
#    if [starting_runner] {
#        aggregate {
#             task_id => "%{host_name}"
#             map_action => "create"
#             code => "map['start_timestamp'] = event['@timestamp']"
#       }
#    }
#    if [ending_runner] {
#        aggregate {
#             task_id => "%{host_name}"
#             map_action => "update"
#             code => "event['duration'] = event['@timestamp'] - map['start_timestamp']"
#             code => "event.set('timestamp_runner_aggragated_start', map['duration'])"
#            end_of_task => true
#        }        
#    }
#}



filter {
    if [elapsed_time] {
         ruby {
            code => '
                event.set("[elapsed_hr]", Time.at(event.get("[elapsed_time]")).utc.strftime("%T.%L"))
            '
        }
    }
}


#filter {
#    if "STARTING-RUNNER" in [tags] {
#            mutate { add_field => { "runner" => "%{[automation][runner]}" } }
#            aggregate {
#            task_id => "%{runner}"
#            code => "map['startstamp'] = event.get('@timestamp')"
#            map_action => "create"
#            add_tag => "metric"
#        }
#    }
# }

#filter {
#    if "ENDING-RUNNER" in [tags] {
#        mutate { add_field => { "runner" => "%{[automation][runner]}" } }
#        aggregate {
#            task_id => "%{runner}"
#            code => 'event_set("time_millis", ((Time.parse(event.get("@timestamp")).to_f * Time.parse(map["startstamp"]).to_f) * 1000).to_i)'
#            map_action => "create"
#            end_of_task => true
#            add_tag => "metric"
#       }
#   }
#}    

#filter {
#    if "STARTING-RUNNER" in [tags] {
#        mutate { add_field => { "runner" => "%{[automation][runner]}" } }
#        aggregate {
#            task_id => "%{runner}"
#            map_action => "create"
#            code => "map['start_timestamp'] = event['@timestamp']"
#        }
#}
#    else if "ENDING-RUNNER" in [tags] {
#        mutate { add_field => { "runner" => "%{[automation][runner]}" } }
#        aggregate {
#            task_id => "%{runner}"
#            map_action => "update"
#            code => 'event.set("[elapsed_hr1]", event.get["@timestamp"] - map["start_timestamp"])'
#            end_of_task => true
#        }
#    }
#}

#'event.set("[nuix_log][host]", event.get("[agent][hostname]"))'

########################
#filter {

#    mutate { add_field => { "runner" => "%{[automation][runner]}" } }
#    
#    elapsed {
#      start_tag => "STARTING-RUNNER"
#      end_tag => "ENDING-RUNNER"
#      periodic_flush => true
#      unique_id_field => "runner"
#      timeout => 86400
#      new_event_on_match => false
#    }
#    
#    elapsed {
#      start_tag => "STARTING-STAGE"
#      end_tag => "ENDING-STAGE"
#      periodic_flush => true
#      unique_id_field => "runner"
#      timeout => 86400
#      new_event_on_match => false
#    }
#    
#    if [elapsed_time] {
#         ruby {
#            code => '
#                event.set("[elapsed_hr]", Time.at(event.get("[elapsed_time]")).utc.strftime("%T.%L"))
#            '
#        }
#    }
#}






   






filter {
   if "STARTING-RUNNER" in [tags] {
        ruby {
        code => '
            t = event.get("@timestamp")
            event.set("elapsed_timestamp_event_start_runner", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
        }
        mutate {
            add_field => { "elapsed_timestamp_event_end_runner" => "Still Running" }
        }        
        mutate {
            add_field => { "elapsed_hr" => "Still Running" }
        }
    }
  }

filter {
   if "STARTING-STAGE" in [tags] {
        ruby {
        code => '
            t = event.get("@timestamp")
            event.set("elapsed_timestamp_event_start_stage", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
        }
        mutate {
            add_field => { "elapsed_timestamp_event_end_stage" => "Still Running" }
        }        
        mutate {
            add_field => { "elapsed_hr" => "Still Running" }
        }
    }
  }

filter {
   if "ENDING-STAGE" in [tags] {
        ruby {
        code => '
            t = event.get("elapsed_timestamp_start")
            event.set("elapsed_timestamp_event_start_stage", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
    }
  }
}

filter {
   if "ENDING-RUNNER" in [tags] {
        ruby {
        code => '
            t = event.get("elapsed_timestamp_start")
            event.set("elapsed_timestamp_event_start_runner", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
    }
  }
}



filter {
   if "AUTOMATION-FINISHED-STAGE" in [tags] {
        ruby {
        code => '
            t = event.get("@timestamp")
            event.set("elapsed_timestamp_event_end_stage", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
    }
  }
}

filter {
   if "AUTOMATION-FINISHED-RUNNER" in [tags] {
        ruby {
        code => '
            t = event.get("@timestamp")
            event.set("elapsed_timestamp_event_end_runner", Time.at(t.to_f).strftime("%Y-%m-%d %H:%M:%S"))
        '
    }
  }
}

    

filter {
  mutate {
    remove_tag => [ "beats_input_codec_plain_applied" ]
  }
}

output {
  elasticsearch {
    hosts => ["http://${ES_HOST}:9200"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}
